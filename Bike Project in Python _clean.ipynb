{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of a public bike share network using Python and machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### J. Michael Shockley\n",
    "\n",
    "5 March 2019\n",
    "\n",
    "For a public bike share service to function smoothly, bikes and docks at which to anchor them need to be available at stations throughout the network. When popular stations run out of bikes or fill up with them, the functionality of the entire bike share network is decreased. Redistribution of bikes between stations alleviates this issue, yet the redistribution process is expensive and labor intensive. An important logistics problem arises out of predicting which stations that will gain or lose bicycles. A multitude of factors may influence the usage of a public bike share service, and these are no doubt interconnected: geographic location of a station, weather, time of day, day of the week, etc.\n",
    "\n",
    "The goal of this project was to take several well-known data sets of a San Francisco Bay Area bike share company and examine the relationships between trip-by-trip usage data, daily weather conditions, and information about the stations themselves. A year's worth of data from a time period of 09/2014 to 08/2015 helped to build a model predicting hourly rate of change per station.\n",
    "\n",
    "Although these are common data sets, all work below (methodology, code, analysis, conclusions) is my own work. This project was written in Python making use of Pandas and Numpy packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Extract raw data\n",
    "\n",
    "Three files were obtained: trip_data.csv, weather_data.csv, and station_data.csv. The data is imported below as data frames and the .head() method shows the contents of each data set. The trip data file includes a unique trip ID, the start and end date/time of each trip, the corresponding start and end station of each trip, and the subscriber type. The weather data contains various metrics of the weather including total precipitation, cloud cover, wind direction, maximum/mean/mininum temperature, dew point, relative humidity, visibility, and wind speed, and stated weather events for each zip code in which the bike share system operates. The station data contains the station ID, name, geographic location, and number of docks for each bike station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Trip data imported as dataframe TD\n",
    "TD=pd.read_csv(\n",
    "    \"trip_data.csv\", \n",
    "    header=0, \n",
    "    skip_blank_lines=False,\n",
    "    parse_dates=['Start Date','End Date'],\n",
    "    date_parser=lambda d: pd.to_datetime(\n",
    "        d, format=\"%d/%m/%Y %H:%M\", errors=\"coerce\"\n",
    "    )\n",
    ")\n",
    "TD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weather data imported as dataframe WD\n",
    "WD=pd.read_csv(\n",
    "    \"weather_data.csv\", \n",
    "    header=0, \n",
    "    skip_blank_lines=False,\n",
    "    parse_dates=['Date'],\n",
    "    date_parser=lambda d: pd.to_datetime(\n",
    "        d, format=\"%d/%m/%Y\", errors=\"coerce\"\n",
    "    )\n",
    ")\n",
    "WD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Station data imported as dataframe SD\n",
    "SD=pd.read_csv(\n",
    "    \"station_data.csv\", \n",
    "    header=0, \n",
    "    skip_blank_lines=False\n",
    ")\n",
    "SD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Create a single data set of bikes entering and leaving each station, per hour\n",
    "\n",
    "The first step to solving the logistics problem of interest requires transforming the raw trip data into an hourly change in bike count per station. This is calculated by counting the bikes entering and leaving each station for each hour during the time period. The next step is to merge the data sets using commmonalities between the data sets as join keys. This will serve as a template for later incorporating weather data (section 3).\n",
    "\n",
    "First, the trip data (TD) is modified by correcting for stations that changed station ID over the time period. The .apply() method is used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify rows in trip data (TD) for stations that changed station ID over the time period\n",
    "REPLACE_MAP = {23:85, 25:86, 49:87, 69:88, 72:90, 89:90}\n",
    "def replace_if_changed(station_id):\n",
    "    # returns the value of the replacement, or inputted station ID if not present in the dict\n",
    "    return REPLACE_MAP.get(station_id, station_id) \n",
    "\n",
    "TD['Start Station'] = TD['Start Station'].apply(replace_if_changed)\n",
    "TD['End Station'] = TD['End Station'].apply(replace_if_changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, new columns are added to the trip data (TD) containing date/time data truncated to the hour, creating date/hour combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use .dt.floor method to truncate trip data to the hour.\n",
    "TD['Start Date Truncated']=TD['Start Date'].dt.floor('h')\n",
    "TD['End Date Truncated']=TD['End Date'].dt.floor('h')\n",
    "TD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now new data frames are created to collect the number of bikes entering and leaving each station by counting each date/hour combination for each station. The pandas .groupby() and .count() methods work similarly to the SQL statements GROUP BY and COUNT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_bystation_bystartdate = (pd.DataFrame(TD.groupby(['Start Station','Start Date Truncated'])\n",
    "                            ['Start Date Truncated']\n",
    "                            .count()         \n",
    "                            .fillna(0)))\n",
    "TD_bystation_bystartdate.columns=['Start Count']\n",
    "TD_bystation_bystartdate.reset_index(inplace=True)\n",
    "\n",
    "TD_bystation_byenddate = (pd.DataFrame(TD.groupby(['End Station','End Date Truncated'])\n",
    "                            ['End Date Truncated']\n",
    "                            .count()         \n",
    "                            .fillna(0)))\n",
    "TD_bystation_byenddate.columns=['End Count']\n",
    "TD_bystation_byenddate.reset_index(inplace=True)\n",
    "TD_bystation_byenddate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the hourly start/end trip counts for each station are consolidated into a single data set. First an empty data set is created containing every station ID and every date/hour combination in the one year period. In Pandas the MultiIndex.from_product() method is used, accomplishing a similar result to the CROSS JOIN statement in SQL. This creates an empty multi-index array DFMerge where the indices are station ID and the unique date/hour combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data frame containing the station IDs\n",
    "DFstation=SD['Id']\n",
    "#Create a data frame containing every date/hour combination from 2014-09-01 to 2015-08-31\n",
    "DFtime=pd.date_range(start=TD_bystation_byenddate['End Date Truncated'].min(), end=TD_bystation_byenddate['End Date Truncated'].max(), freq='h')\n",
    "#Create a multi-index array where the indices are the station ID and unique date/hour combinations\n",
    "DFMerge=pd.MultiIndex.from_product([DFstation,DFtime],names=['Station','Date/Hour'])\n",
    "#Convert the multi-level indices to column values \n",
    "DFMerge=pd.DataFrame(index=DFMerge).reset_index()\n",
    "DFMerge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the pd.merge function is used to incorporate the TD_bystation_bystartdate and TD_bystation_byenddate into DFMerge using station ID and date/hour combinations as join keys. This is functionally similar to the LEFT JOIN in SQL. The DFall data frame is created in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFall=pd.merge(left=DFMerge, right=TD_bystation_bystartdate, how='left', on=None, left_on=['Station','Date/Hour'], right_on=['Start Station','Start Date Truncated'])\n",
    "DFall=pd.merge(left=DFall, right=TD_bystation_byenddate, how='left', on=None, left_on=['Station','Date/Hour'], right_on=['End Station','End Date Truncated'])\n",
    "#Remove extraneous columns from the merge and fill in zero values as na\n",
    "DFall=DFall.drop(columns=['Start Station','Start Date Truncated','End Station','End Date Truncated'])\n",
    "DFall=DFall.fillna(0)\n",
    "\n",
    "DFall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new column, Net Bikes Per Hour, is calculated as the difference between incoming and outgoing bike counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFall['Net Bikes Per Hour']=DFall['End Count']-DFall['Start Count']\n",
    "DFall['Net Bikes Per Hour'] = DFall['Net Bikes Per Hour'].astype(int)\n",
    "DFall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Incorporate station information and weather data into the hourly trip data set\n",
    "\n",
    "The DFall data frame contains a count of the bikes entering and leaving each station for each hour in the period between 2014-09-01 to 2015-08-31. Now, station data (SD) and weather data (WD) are merged into the data set.\n",
    "\n",
    "First, the replace_if_changed function is used to add the zip code to the station data (SD) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add zip code column to station data (SD)\n",
    "#Modify rows in trip data (TD) for stations that changed station ID over the time period\n",
    "REPLACE_MAP = {'San Jose':95113, 'Mountain View':94041, 'Palo Alto':94301, 'San Francisco':94107, 'Redwood City':94063}\n",
    "SD['Zip'] = SD['City'].apply(replace_if_changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pd.merge is used to join the station information SD into the hourly trip data set, DFall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFall=pd.merge(left=DFall, right=SD, how='left', left_on=['Station'], right_on=['Id'])\n",
    "#Remove extraneous columns\n",
    "DFall=DFall.drop(columns=['Id','Dock Count'])\n",
    "DFall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join the daily weather data (WD), a column is created to truncate the date/hour data to the date only. This permits the date to be used as a join key. The same is done to the weather data (WD) to avoid any risk of formatting errors. Then the two data sets are merged into a final data frame, DFfinal, using pd.merge(). The column Zip is used as an additional join key to match each station to the weather of its corresponding zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFall['Date']=DFall['Date/Hour'].dt.floor('D')\n",
    "WD['DateTrunc']=WD['Date'].dt.floor('D')\n",
    "DFfinal=pd.merge(left=DFall, right=WD, how='left', on=['Zip','Date'])\n",
    "DFfinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the trip, station, and weather data have been collected into a single dataframe, the relationships between them can be closely studied. A few extra columns are added for the ease of plotting: hour, weekday, and month are extracted from the Date/Hour column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract and create new columns hour, weekday, and month from Date/Hour column\n",
    "DFfinal['hour']=DFfinal['Date/Hour'].dt.hour\n",
    "DFfinal['weekday']=DFfinal['Date/Hour'].dt.weekday+1\n",
    "DFfinal['month']=DFfinal['Date/Hour'].dt.month\n",
    "#Calculate absolute value of Net Bikes Per Hour column\n",
    "DFfinal['Abs Net Bikes Per Hour']=DFfinal['Net Bikes Per Hour'].abs()\n",
    "#Convert hour of day and weekday to numeric string\n",
    "DFfinal['weekday_str']=DFfinal['weekday'].apply(str)\n",
    "DFfinal['hour_str']=DFfinal['hour'].apply(str)\n",
    "#Convert weekday to string\n",
    "conditions = [\n",
    "    (DFfinal['weekday_str']=='1'),\n",
    "    (DFfinal['weekday_str']=='2'),\n",
    "    (DFfinal['weekday_str']=='3'),\n",
    "    (DFfinal['weekday_str']=='4'),\n",
    "    (DFfinal['weekday_str']=='5'),\n",
    "    (DFfinal['weekday_str']=='6'),\n",
    "    (DFfinal['weekday_str']=='7')]\n",
    "     \n",
    "choices = ['Mon', 'Tues', 'Wed','Thur','Fri','Sat','Sun']\n",
    "DFfinal['WeekdayName'] = np.select(conditions, choices)\n",
    "\n",
    "DFfinal['Mean VisibilityMiles']=DFfinal['Mean VisibilityMiles'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFfinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Relationships\n",
    "\n",
    "### Geographic locations of bike stations\n",
    "\n",
    "The station data (SD) data frame includes the longitude and latitude of each station. Using the Cartopy package, each station can be plotted on a map of the local area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from cartopy.io.img_tiles import OSM\n",
    "\n",
    "# Initialize figure and specify Open Street Map as map tile source\n",
    "plt.figure(figsize=(12, 12))\n",
    "imagery = OSM()\n",
    "ax = plt.axes(projection=imagery.crs)\n",
    "# Define axes in terms of longitude and latitude and add map tile imagery\n",
    "ax.set_extent([-122.75, -121.5,37, 38])\n",
    "ax.add_image(imagery, 9,interpolation='spline36')\n",
    "# Add scatter plot of station locations based longitude and latitude\n",
    "plt.scatter(SD['Long'],SD['Lat'],transform=ccrs.Geodetic(),color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters of bike share stations exist in San Francisco, Redwood City, Palo Alto, Mountain View, and San Jose. This map confirms the 'City', 'Lat', and 'Long' columns conform to one another.\n",
    "\n",
    "#### San Francisco bike stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "imagery = OSM()\n",
    "ax = plt.axes(projection=imagery.crs)\n",
    "ax.set_extent([-122.435, -122.37,37.765, 37.81])\n",
    "ax.add_image(imagery, 14,interpolation='spline36')\n",
    "plt.scatter(SD['Long'],SD['Lat'],s=100,transform=ccrs.Geodetic(),color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The stations in San Francisco are located in the downtown area, with some stations closer to public transport options and landmarks than others.\n",
    "### Bike share use by day of the week: two stations\n",
    "\n",
    "Two stations are selected for analysis: station 65, located in close proximity to a Caltrain commuter rail station, and station 70, located a few blocks away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset DFfinal to stations 65 and 70\n",
    "DFfinal_65_70 = DFfinal[DFfinal[\"Station\"].isin([65, 70])]\n",
    "#Subset DFfinal to stations 65 and 70 between 5am and 9pm\n",
    "DFfinal_65_70_day = DFfinal[DFfinal[\"Station\"].isin([65, 70]) & DFfinal['hour'].isin(list(range(5,21)))]\n",
    "#Subset DFfinal to stations 65 and 70 between 5am and 9pm\n",
    "DFfinal_day=DFfinal[DFfinal['hour'].isin(list(range(5,21)))]\n",
    "#Subset SD to stations 65 and 70\n",
    "SD_65_70=SD[SD['Id'].isin([65,70])]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "imagery = OSM()\n",
    "ax = plt.axes(projection=imagery.crs)\n",
    "ax.set_extent([-122.42, -122.38,37.765, 37.79])\n",
    "ax.add_image(imagery, 15,interpolation='spline36')\n",
    "plt.scatter(SD_65_70['Long'],SD_65_70['Lat'],s=100,transform=ccrs.Geodetic(),color='k')\n",
    "#Label stations\n",
    "plt.text(-122.401717,37.771058,\"65\",fontsize=28,transform=ccrs.Geodetic())\n",
    "plt.text(-122.394260,37.776617,\"70\",fontsize=28,transform=ccrs.Geodetic())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the two selected stations (Station IDs 65 and 70), the hourly change in bikes per station is plotted below as a scatter plot as a function of time of day (24-hour scale) between 5am and 9pm. The line of best fit is plotted as well in yellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "import skmisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot with line of best fit shown in yellow\n",
    "(p9.ggplot(data=DFfinal_65_70,\n",
    "          mapping=p9.aes(x=\"hour\", y=\"Net Bikes Per Hour\"))\n",
    "    + p9.geom_point(alpha=0.1)\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "    + p9.geom_smooth(method=\"loess\",size=1, color=\"yellow\",alpha=1,se=True,span=0.4,level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stations 65 and 70, the highest rate of change of bikes per station occurs during the morning and evening rush hours. The least amount of usage is at night. Interestingly, the stations have differing trends in morning/evening usage due to their location: stations 65 is located near the financial district, implying riders are commuting to these stations in the morning and vice/versa. Station 70 is located next to a commuter rail station, implying riders are commuting from this station in the morning. Importantly, this shows that each station has unique ridership behavior based on its geographic location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=DFfinal_65_70_day,\n",
    "          mapping=p9.aes(x=\"hour_str\", y=\"Net Bikes Per Hour\"))\n",
    "    #+ p9.geom_point(alpha=0.1)\n",
    "    + p9.geom_boxplot()\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "    +p9.xlab(\"Hour of Day\")\n",
    "    +p9.scale_x_discrete(limits=[str(i) for i in list(range(5,21))])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots reveal richer statistical detail than previous scatter plot, which has many overlapping data points. Each box plot shows the outliers, first quartile, median, and third quartile, quantitatively displaying the pattern of ridership over the course of a day.\n",
    "### Bike share usage by day of the week: two stations\n",
    "\n",
    "A similar plot per day of the week shows that most ridership occurs on weekdays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=DFfinal_65_70_day,\n",
    "          mapping=p9.aes(x=\"WeekdayName\", y=\"Net Bikes Per Hour\"))\n",
    "    #+ p9.geom_point(alpha=0.1)\n",
    "    + p9.geom_boxplot()\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "    +p9.scale_x_discrete(limits=['Sun','Mon','Tues','Wed','Thur','Fri','Sat'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of weather on ridership\n",
    "As 24 columns exist in the original weather data (WD) set, there is a lot of information to consider. Certain columns, however, may be redundant. For example, several sets of weather data is in triplicate min/mean/max form, and related variables may already correlate well to one another. A correlation matrix can show these relationships and be used to avoid redundancies in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df,size=10):\n",
    "    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot'''\n",
    "\n",
    "    corr = df.corr()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    cax = ax.matshow(corr, vmin=-1, vmax=1)\n",
    "    fig.colorbar(cax)\n",
    "    #ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns);\n",
    "    \n",
    "plot_corr(WD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix shows that clusters of weather data correlate well to one another. Min/mean/max temperature and dew point correlate well to another another, as do humidity, sea level pressure, and wind speed. For this reason, only the mean of each of these values will be analyzed.\n",
    "\n",
    "#### Wind Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=DFfinal_65_70_day,\n",
    "          mapping=p9.aes(x=\"Mean Wind SpeedMPH\", y=\"Abs Net Bikes Per Hour\"))\n",
    "    #+ p9.geom_point(alpha=0.1)\n",
    "    + p9.geom_point(alpha=0.1)\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "    + p9.geom_smooth(method=\"loess\",size=1, color=\"yellow\",alpha=1,se=True,span=0.6,level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean wind speed, plotted with a best fit line and 90% confidence interval, does not have a strong effect on ridership for stations 65 and 70. Above about 15 MPH, the confidence interval expands -- this is an artefact of having fewer data points above this wind speed.\n",
    "\n",
    "#### Mean Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(p9.ggplot(data=DFfinal_65_70_day,\n",
    "          mapping=p9.aes(x=\"Mean TemperatureF\", y=\"Abs Net Bikes Per Hour\"))\n",
    "    #+ p9.geom_point(alpha=0.1)\n",
    "    + p9.geom_point(alpha=0.1)\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "    + p9.geom_smooth(method=\"loess\",size=1, color=\"yellow\",alpha=1,se=True,span=0.6,level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both stations 65 and 70, the ridership occurs most often between 50 and 70 degrees F. This is likely a function of comfort and of the stable temperatures in this part of California, with fewer data points below 50 degrees and above 70 degrees.\n",
    "\n",
    "#### Dew Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=DFfinal_65_70_day,\n",
    "          mapping=p9.aes(x=\"MeanDew PointF\", y=\"Abs Net Bikes Per Hour\"))\n",
    "    #+ p9.geom_point(alpha=0.1)\n",
    "    + p9.geom_point(alpha=0.1)\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "    + p9.geom_smooth(method=\"loess\",size=1, color=\"yellow\",alpha=1,se=True,span=0.6,level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the temperature data above, the dew point largely falls between 35 and 60 degrees F, all of which are comfortable. With few data points outside this range, it is unclear if dew point has an effect on ridership. If this project analyzed bike share data in Washington DC, this relationship would be very different.\n",
    "\n",
    "#### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=DFfinal_65_70_day,\n",
    "          mapping=p9.aes(x=\"PrecipitationIn\", y=\"Abs Net Bikes Per Hour\"))\n",
    "    + p9.geom_point(alpha=0.1)\n",
    "    + p9.facet_wrap(\"Station\")\n",
    "+ p9.geom_smooth(data=DFfinal_65_70_day[DFfinal_65_70_day['PrecipitationIn']<0.5], method=\"lm\",size=1, color=\"yellow\",alpha=1,se=True,span=0.9,level=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precipitation has a strong effect on ridership at stations 65 and 70. Above 0.5 inches of rain, ridership drops off considerably. The line of best fit is to daily precipitation values below 0.5.\n",
    "\n",
    "## 5 Summary and recommendations for future work\n",
    "\n",
    "The present project has revealed relationships within a San Francisco bay area bike share network during the period of 09/2014 to 08/2015. The geographic location of stations, time of day, day of the week, and weather parameters all affect the ridership numbers to greater or lesser extents.\n",
    "\n",
    "To fully leverage this data for the logistics problem stated in the introduction, a regression model may be used to fit and predict the Net Bikes Per Hour data to the many features that have been shown to influence it. Such a model would almost certainly need to be performed an a station-by-station basis, given the high variability between stations based on geographic location. This is left as a consideration for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
